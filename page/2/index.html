<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "3927c7df"
    });
  daovoice('update');
  </script>


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="TomorrowLi's Blog" type="application/atom+xml">





<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>
<meta property="og:type" content="website">
<meta property="og:title" content="TomorrowLi&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="TomorrowLi&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TomorrowLi&#39;s Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title>TomorrowLi's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
    <a href="https://github.com/TomorrowLi" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">TomorrowLi's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/ScrapyZufang/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/ScrapyZufang/" itemprop="url">爬取房天下的租房信息，并对数据进行可视化展示</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Scrapy/" itemprop="url" rel="index">
                    <span itemprop="name">Scrapy</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  576
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、首先准备需要的库</p>
<pre><code>1、pandas//是python的一个数据分析包
2、matplotlib//是一个 Python 的 2D绘图库，它以各种硬拷贝格式和跨平台的交互式环境生成出版质量级别的图形。
3、jieba//jieba(结巴)是一个强大的分词库,完美支持中文分词
4、wordcloud//基于Python的词云生成类库
5、numpy//NumPy系统是Python的一种开源的数值计算扩展。这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix））
</code></pre><p>二、用scrapy创建一个项目</p>
<pre><code>scrapy startproject zufangSpider

scrapy genspider zufang http://zu.sh.fang.com/cities.aspx
</code></pre><p>三、实现房天下的的数据爬取</p>
<pre><code>#初始化url
def start_requests(self):
    yield scrapy.Reques(self.city_url,callback=self.get_city)
#调用get_city()方法
 def get_city(self,response):
    url=response.xpath(&apos;/html/body/div[3]/div[1]/a/@href&apos;).extract()
    #循环热门城市
    for i in url:
        product={
            &apos;city&apos;:i
        }
        yield scrapy.Request(product[&apos;city&apos;],callback=self.city_parse, dont_filter=True)
        #循环爬取每一页
        for j in range(2,10):
            next_url=product[&apos;city&apos;]+&apos;house/i3%s&apos;%j
            yield scrapy.Request(next_url,callback=self.city_parse,dont_filter=True)
#调用city_parse()方法获取每一页的数据
def city_parse(self, response):
    zufang = response.xpath(&apos;//div[@class=&quot;houseList&quot;]&apos;)
    for fangzi in zufang:
        title=fangzi.xpath(&apos;//p[@class=&quot;title&quot;]/a/text()&apos;).extract()
        area =fangzi.xpath(&apos;//p[@class=&quot;gray6 mt20&quot;]/a[1]/span[1]/text()&apos;).extract()
        rent_style = fangzi.xpath(&apos;//p[@class=&quot;font16 mt20 bold&quot;]/text()[1]&apos;).extract()
        house_type= fangzi.xpath(&apos;//p[@class=&quot;font16 mt20 bold&quot;]/text()[2]&apos;).extract()
        house_area = fangzi.xpath(&apos;//p[@class=&quot;font16 mt20 bold&quot;]/text()[3]&apos;).extract()
        if fangzi.xpath(&apos;//p[@class=&quot;font16 mt20 bold&quot;]/text()[4]&apos;):
            orientation = fangzi.xpath(&apos;//p[@class=&quot;font16 mt20 bold&quot;]/text()[4]&apos;).extract()
        else:
            orientation=&apos;&apos;
        price = fangzi.xpath(&apos;//p[@class=&quot;mt5 alingC&quot;]/span/text()&apos;).extract()
        for i in range(len(title)):
            item = ZufangScrapyItem()
            item[&apos;title&apos;]=title[i]
            item[&apos;area&apos;]=area[i]
            item[&apos;rent_style&apos;]=rent_style[i].strip()
            item[&apos;house_type&apos;]=house_type[i]
            item[&apos;house_area&apos;]=house_area[i]
            item[&apos;orientation&apos;]=orientation[i].strip()
            item[&apos;price&apos;]=price[i]
            yield item
</code></pre><p>四、对数据进行可视化</p>
<pre><code>1、首先运行 scrapy crawl zufang -o zufang.csv

把数据保存成csv文件

2、import pandas as pd
data=pd.read_csv(r&apos;H:\Python\zufang_scrapy\zufang.csv&apos;)
data.head()
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/zufang.jpg?raw=true" alt="zufang.csv"></p>
<pre><code>3、import matplotlib.pyplot as plt
plt.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;]
data[&apos;orientation&apos;].value_counts().plot(kind=&apos;barh&apos;,rot=0)
plt.show()
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/zufang1.jpg?raw=true" alt="image"></p>
<pre><code>4、final=&apos;&apos;
stopword=[&apos;NaN&apos;]
for n in range(data.shape[0]):
seg_list=list(jieba.cut(data[&apos;area&apos;][n]))
for seg in seg_list:
    if seg not in stopword:
        final=final+seg+&apos; &apos;
my_wordcloud=WordCloud(collocations=False,font_path=r&apos;C:\Windows\Fonts\simfang.ttf&apos;,width=2000,height=600,margin=2).generate(final)
plt.imshow(my_wordcloud)
plt.axis(&apos;off&apos;)
plt.show()
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/zufang2.jpg?raw=true" alt="image"></p>
<p>详细代码：可以访问我的 <a href="https://github.com/TomorrowLi/ScraptZufaang" target="_blank" rel="noopener">GitHub</a> 地址</p>

          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/scrapyZhihu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/scrapyZhihu/" itemprop="url">利用scrapy爬取知乎用户信息并存储在mongodb数据库中</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  660
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、首先在setting.py中修改True改为False</p>
<pre><code># Obey robots.txt rules
#允许爬取robots.txt文件内不能爬取的资源
ROBOTSTXT_OBEY = True
#知乎是由反扒措施的必须添加User-agent以及authorization
DEFAULT_REQUEST_HEADERS = {
  &apos;Accept&apos;: &apos;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&apos;,
  &apos;Accept-Language&apos;: &apos;en&apos;,
    &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36&apos; ,
    &apos;authorization&apos;:&apos;Bearer 2|1:0|10:1521707334|4:z_c0|80:MS4xS1NYS0FnQUFBQUFtQUFBQVlBSlZUVWEzb0Z0ZDl0MGhaa0VJOWM0ODhiejhRenVUd0tURnFnPT0=|98bb6f4900c1b4b52ece0282393ede5e31046c9a90216e69dec1feece8086ee0&apos;
}
</code></pre><p>二、编写spider的项目文件</p>
<p>1、zhihu_user.py</p>
<pre><code># -*- coding: utf-8 -*-
import json

import scrapy
from scrapy import Spider,Request

from ..items import UserItem


class ZhihuUserSpider(Spider):
    name = &apos;zhihu_user&apos;
    allowed_domains = [&apos;www.zhihu.com&apos;]
    start_urls = [&apos;http://www.zhihu.com/&apos;]
    start_user=&apos;excited-vczh&apos;
    user_url=&apos;https://www.zhihu.com/api/v4/members/{user}?include={include}&apos;
    user_query=&apos;allow_message,is_followed,is_following,is_org,is_blocking,employments,answer_count,follower_count,articles_count,gender,badge[?(type=best_answerer)].topics&apos;
    follows_url=&apos;https://www.zhihu.com/api/v4/members/{user}/followees?include={include}&amp;offset={offset}&amp;limit={limit}&apos;
    follows_query=&apos;data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics&apos;
    followers_url=&apos;https://www.zhihu.com/api/v4/members/{user}/followers?include={include}&amp;offset={offset}&amp;limit={limit}&apos;
    followers_query=&apos;data[*].answer_count,articles_count,gender,follower_count,is_followed,is_following,badge[?(type=best_answerer)].topics&apos;
    def start_requests(self):
        yield Request(self.user_url.format(user=self.start_user,include=self.user_query),self.parse_user)
        yield Request(self.follows_url.format(user=self.start_user,include=self.follows_query,offset=0,limit=20),callback=self.parse_query)
    def parse_user(self, response):
        result=json.loads(response.text)
        item=UserItem()
        for field in item.fields:
            if field in result.keys():
                item[field]=result.get(field)
        yield item
        yield Request(self.follows_url.format(user=result.get(&apos;url_token&apos;),include=self.follows_query,offset=0,limit=20),callback=self.parse_query)
        yield Request(self.followers_url.format(user=result.get(&apos;url_token&apos;),include=self.followers_query,offset=0,limit=20),callback=self.parse_querys)
    def parse_query(self, response):
        results=json.loads(response.text)
        if &apos;data&apos; in results.keys():
            for result in results.get(&apos;data&apos;):
                yield Request(self.user_url.format(user=result.get(&apos;url_token&apos;),include=self.user_query),callback=self.parse_user)
        if &apos;paging&apos; in results.keys() and results.get(&apos;paging&apos;).get(&apos;is_end&apos;)==False:
            next_page=results.get(&apos;paging&apos;).get(&apos;next&apos;)
            yield Request(next_page,self.parse_query)
    def parse_querys(self, response):
        results=json.loads(response.text)
        if &apos;data&apos; in results.keys():
            for result in results.get(&apos;data&apos;):
                yield Request(self.user_url.format(user=result.get(&apos;url_token&apos;),include=self.user_query),callback=self.parse_user)
        if &apos;paging&apos; in results.keys() and results.get(&apos;paging&apos;).get(&apos;is_end&apos;)==False:
            next_page=results.get(&apos;paging&apos;).get(&apos;next&apos;)
            yield Request(next_page,self.parse_querys)
</code></pre><p>2、items.py</p>
<pre><code># -*- coding: utf-8 -*-

# Define here the models for your scraped items
#
# See documentation in:
# https://doc.scrapy.org/en/latest/topics/items.html

import scrapy
from scrapy import Item,Field

class UserItem(Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    headline=Field()
    avatar_url=Field()
    name=Field()
    type=Field()
    url_token=Field()
    user_type=Field()
</code></pre><p>3、pipelines.py</p>
<pre><code># -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don&apos;t forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html


import pymongo

class MongoPipeline(object):

    collection_name = &apos;scrapy_items&apos;

    def __init__(self, mongo_uri, mongo_db):
        self.mongo_uri = mongo_uri
        self.mongo_db = mongo_db

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            mongo_uri=crawler.settings.get(&apos;MONGO_URI&apos;),
            mongo_db=crawler.settings.get(&apos;MONGO_DATABASE&apos;)
        )

    def open_spider(self, spider):
        self.client = pymongo.MongoClient(self.mongo_uri)
        self.db = self.client[self.mongo_db]

    def close_spider(self, spider):
        self.client.close()

    def process_item(self, item, spider):
        self.db[&apos;user&apos;].update({&apos;url_token&apos;:item[&apos;url_token&apos;]},{&apos;$set&apos;:item},True)
        #self.db[self.collection_name].insert_one(dict(item))
        return item
</code></pre><p>4、setting.py</p>
<pre><code>BOT_NAME = &apos;zhihu&apos;

SPIDER_MODULES = [&apos;zhihu.spiders&apos;]
NEWSPIDER_MODULE = &apos;zhihu.spiders&apos;
MONGO_URI=&apos;localhost&apos;
MONGO_DATABASE=&apos;zhihu&apos;
</code></pre><p>三、最后启动setting.py中的</p>
<pre><code>ITEM_PIPELINES = {
       &apos;zhihu.pipelines.MongoPipeline&apos;: 300,
}
#去掉注释
</code></pre><p>四、结果展示</p>
<p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/zhihuMongodb.PNG?raw=true" alt="image"></p>

          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/scrapy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/scrapy/" itemprop="url">scrapy爬虫框架的简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/scrapy/" itemprop="url" rel="index">
                    <span itemprop="name">scrapy</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  529
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、安装scrapy所依赖的库</p>
<pre><code>1、安装wheel
    pip install wheel
2、安装lxml
    https://pypi.python.org/pypi/lxml/4.1.0
3、安装pyopenssl
    https://pypi.python.org/pypi/pyOpenSSL/17.5.0
4、安装Twisted
    https://www.lfd.uci.edu/~gohlke/pythonlibs/
5、安装pywin32
    https://sourceforge.net/projects/pywin32/files/
6、安装scrapy
    pip install scrapy
</code></pre><p>二、爬虫举例</p>
<p>1、创建项目</p>
<pre><code>scrapy startproject zhihu
</code></pre><p>2、创建spider项目程序</p>
<pre><code>cd zhihu
scrapy genspider zhihuspider www.zhihu.com
</code></pre><p>3、自动创建目录及文件</p>
<p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/scrapy.jpg?raw=true" alt="image"></p>
<p>4、生成的爬虫具有基本的结构，我们可以直接在此基础上编写代码</p>
<pre><code># -*- coding: utf-8 -*-
import scrapy


class ZhihuSpider(scrapy.Spider):
name = &quot;zhihuspider&quot;
allowed_domains = [&quot;zhihu.com&quot;]
start_urls = [&apos;http://www.zhihu.com/&apos;]

def parse(self, response):
    pass
</code></pre><p>5、然后，可以我们按照name来运行爬虫</p>
<pre><code>scrapy crawl &apos;zhihuspider&apos;
</code></pre><p>二、项目文件详细分析</p>
<p>1、spriders文件夹</p>
<pre><code>#项目文件,以后的代码都要在这里写入
zhihuspider.py
</code></pre><p>2、items.py</p>
<pre><code>from scrapy import Item,Field

class UserItem(Item):
    #Item 对象是种简单的容器，保存了爬取到得数据。 其提供了 类似于词典(dictionary-like) 的API以及用于声明可用字段的简单语法。
    # define the fields for your item here like:
    #爬取所需要的数据的名称在这里定义，很像字典
    # name = scrapy.Field()
</code></pre><p>3、pipelines.py</p>
<p>&#160; &#160; &#160; &#160; 当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理</p>
<p>###主要是处理以下4点任务</p>
<p>1.清理HTML数据</p>
<p>2.验证爬取的数据(检查item包含某些字段)</p>
<p>3.查重(并丢弃)</p>
<p>4.将爬取结果保存到数据库中</p>
<pre><code>#存到mogodb数据库

import pymongo

class MongoPipeline(object):

    collection_name = &apos;scrapy_items&apos;

    def __init__(self, mongo_uri, mongo_db):
        self.mongo_uri = mongo_uri
        self.mongo_db = mongo_db

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            mongo_uri=crawler.settings.get(&apos;MONGO_URI&apos;),
            mongo_db=crawler.settings.get(&apos;MONGO_DATABASE&apos;, &apos;items&apos;)
        )

    def open_spider(self, spider):
        self.client = pymongo.MongoClient(self.mongo_uri)
        self.db = self.client[self.mongo_db]

    def close_spider(self, spider):
        self.client.close()

    def process_item(self, item, spider):
        self.db[self.collection_name].insert_one(dict(item))
        return item
</code></pre><p>4、settings.py</p>
<p>&#160; &#160; &#160; &#160; 用于设置常量的,例如 mongodb 的 url 和 database</p>
<pre><code>BOT_NAME = &apos;zhihu&apos;

SPIDER_MODULES = [&apos;zhihu.spiders&apos;]

NEWSPIDER_MODULE = &apos;zhihu.spiders&apos;

MONGO_URI=&apos;localhost&apos;

MONGO_DATABASE=&apos;zhihu&apos;

#默认是True的这个变量是用来是否爬robot文件的改为False是允许的意思
ROBOTSTXT_OBEY = True
</code></pre>
          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/python/" itemprop="url">python爬虫的精华篇</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,447
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  5
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="最简单的反爬手段"><a href="#最简单的反爬手段" class="headerlink" title="最简单的反爬手段"></a>最简单的反爬手段</h2><p>&#160; &#160; &#160; &#160; 有一部分网站（甚至包括部分商业网站）其实并没有真正认真做过反爬虫这件事情，你不需要做任何伪装，即可分分钟抓光它的网站。面对这样的网站，你只需要开大马力抓抓抓就好了，如果处于情怀考虑，你可以抓的慢一点，让它的服务器别太累。</p>
<p>&#160; &#160; &#160; &#160; 除去这样的情况，最简单的反爬虫机制，应该算是U-A校验了。浏览器在发送请求的时候，会附带一部分浏览器及当前系统环境的参数给服务器，这部分数据放在HTTP请求的header部分。</p>
<h2 id="通过访问频度反爬"><a href="#通过访问频度反爬" class="headerlink" title="通过访问频度反爬"></a>通过访问频度反爬</h2><p>&#160; &#160; &#160; &#160; 这种反爬虫机制的原理是，真人通过浏览器访问网站的速度（相对程序来讲）是很慢的，所以如果你一秒访问了200个页面——这里不代表实际数值，只是表达在较短时间内发送了较多请求，具体阈值需要具体考虑——服务器则认为你是一个爬虫。</p>
<p>适用情况：限制频率情况。</p>
<p>Requests，Urllib2都可以使用time库的sleep()函数：</p>
<pre><code>import time
time.sleep(1)
</code></pre><h2 id="通过验证码限制"><a href="#通过验证码限制" class="headerlink" title="通过验证码限制"></a>通过验证码限制</h2><p>&#160; &#160; &#160; &#160; 这样的方式与上面的方式相比更加难处理的是，不管你的访问频次怎么样，你都需要输入验证码才行。比如12306，不管你是登录还是购票，也不论你是第一次还是第一万次购买，你都需要输入一个验证码之后才能继续。这时候，在绝大部分情况下，你必须要想办法识别验证码了。之所以说是大多数情况下，是因为在极少数极少数情况下（尤其是政府网站），棒槌程序员通过客户端的JavaScript来校验验证码，这时候对你的爬虫来讲，其实是没有验证码的（比如中国商标网）。除开你遇到这种几乎可以忽略不计的棒槌开发的网站，其他时候你只有通过识别验证码来继续后面的操作了。</p>
<p>1、首先你可以找到验证吗图片的url<br>2、把图片保存到本地,然后手动输入验证码达到验证的效果，可以参考我前面的文章，有关豆瓣验证码的处理</p>
<h2 id="通过经常变换网页结构"><a href="#通过经常变换网页结构" class="headerlink" title="通过经常变换网页结构"></a>通过经常变换网页结构</h2><p>&#160; &#160; &#160; &#160; 常见于一些社交网站，他们会经常更换网页的结构，如果你是通过依赖网页结构来解析需要的数据（不幸的是大部分情况下我们都需要通过网页结构来解析需要的数据），则在原本的网页位置找不到原本需要的内容。这时候，要分不同情况具体处理了。如果你只打算一次性抓取特定数据，那么赶快行动，它以后结构变了无所谓，反正你也不打算在抓它一次。如果是需要持续性抓取的网站，就要仔细思考下应对方案了。一个简单粗暴但是比较费力的办法是，写一个校验脚本，定期校验网页结构，如果与预期不符，那么赶快通知自己（或者特定开发者）修改解析部分，以应对网页结构变化。</p>
<h2 id="对于Ajax请求的处理"><a href="#对于Ajax请求的处理" class="headerlink" title="对于Ajax请求的处理"></a>对于Ajax请求的处理</h2><p>&#160; &#160; &#160; &#160; 对于“加载更多”情况，使用Ajax来传输很多数据。它的工作原理是：从网页的url加载网页的源代码之后，会在浏览器里执行JavaScript程序。这些程序会加载更多的内容，“填充”到网页里。这就是为什么如果你直接去爬网页本身的url，你会找不到页面的实际内容。这里，若使用Google Chrome分析”请求“对应的链接(方法：右键→审查元素→Network→清空，点击”加载更多“，出现对应的GET链接寻找Type为text/html的，点击，查看get参数或者复制Request URL)，循环过程。</p>
<h2 id="自动化测试工具Selenium"><a href="#自动化测试工具Selenium" class="headerlink" title="自动化测试工具Selenium"></a>自动化测试工具Selenium</h2><p>&#160; &#160; &#160; &#160; Selenium是一款自动化测试工具。它能实现操纵浏览器，包括字符填充、鼠标点击、获取元素、页面切换等一系列操作。总之，凡是浏览器能做的事，Selenium都能够做到。</p>
<h2 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h2><p>&#160; &#160; &#160; &#160; 适用情况：限制IP地址情况，也可解决由于“频繁点击”而需要输入验证码登陆的情况。<br>这种情况最好的办法就是维护一个代理IP池，网上有很多免费的代理IP，良莠不齐，可以通过筛选找到能用的。对于“频繁点击”的情况，我们还可以通过限制爬虫访问网站的频率来避免被网站禁掉。</p>
<pre><code>proxies = {&apos;http&apos;:&apos;http://XX.XX.XX.XX:XXXX&apos;}
Requests：//强烈推荐使用
import requests
response = requests.get(url=url, proxies=proxies)
Urllib2：
import urllib2
proxy_support = urllib2.ProxyHandler(proxies)
opener = urllib2.build_opener(proxy_support, urllib2.HTTPHandler)
urllib2.install_opener(opener) # 安装opener，此后调用urlopen()时都会使用安装过的opener对象
response = urllib2.urlopen(url)
</code></pre><h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>&#160; &#160; &#160; &#160; 由于Python的是跨平台的，自然也应该提供一个跨平台的多进程支持。multiprocessing模块就是跨平台版本的多进程模块。<br>multiprocessing提供模块一个了Process类来代表一个进程对象，下面的例子演示了启动一个子进程并等待其结束：<br>    from multiprocessing import Process<br>    import os</p>
<pre><code>#子进程要执行的代码
def run_proc(name):
    print &apos;Run child process %s (%s)...&apos; % (name, os.getpid())

if __name__==&apos;__main__&apos;:
    print &apos;Parent process %s.&apos; % os.getpid()
    p = Process(target=run_proc, args=(&apos;test&apos;,))
    print &apos;Process will start.&apos;
    p.start()
    p.join()
    print &apos;Process end.&apos;
</code></pre><p>执行结果如下：</p>
<pre><code>Parent process 928.
Process will start.
Run child process test (929)...
Process end.
</code></pre><p>参考 <a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143192823818768cd506abbc94eb5916192364506fa5d000" target="_blank" rel="noopener">廖雪峰</a> 的python教程</p>

          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/python-student/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/python-student/" itemprop="url">今日头条上的美女图片进行爬取</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  549
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          想要密码,请联系我
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2021/07/18/python-student/">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/pojie/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/pojie/" itemprop="url">百度文库下载和百度云加速下载</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/破解软件/" itemprop="url" rel="index">
                    <span itemprop="name">破解软件</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  113
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="一、百度文库、道客巴巴登免费下载"><a href="#一、百度文库、道客巴巴登免费下载" class="headerlink" title="一、百度文库、道客巴巴登免费下载"></a>一、百度文库、道客巴巴登免费下载</h3><p>&#160;&#160;&#160;&#160;1、百度文库下载：首先进入你要下载的文档页面</p>
<pre><code>例如:https://wenku.baidu.com/view/eeb5d53069eae009591bec34.html?from=search
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/baidu.PNG?raw=true" alt="image"></p>
<p>&#160;&#160;&#160;&#160;2、把图中的链接复制到冰点文库的下载</p>
<p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/baidu1.PNG?raw=true" alt="image"></p>
<p>&#160;&#160;&#160;&#160;3、文件下载地址：</p>
<pre><code>链接：https://pan.baidu.com/s/1G0zTlsG61ipGnGfmHPEijw
密码: bzjm
</code></pre><h3 id="二、百度云加速下载"><a href="#二、百度云加速下载" class="headerlink" title="二、百度云加速下载"></a>二、百度云加速下载</h3><p>&#160;&#160;&#160;&#160;1、首先要登陆你的百度云账号</p>
<p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/baiduyun.PNG?raw=true" alt="image"></p>
<pre><code>链接：https://pan.baidu.com/s/1Lzm5_8lRPHO0e5r38rl-3A
密码: mcc5
</code></pre>
          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/nuomi-meituan-dazhong/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/nuomi-meituan-dazhong/" itemprop="url">对百度糯米、美团、大众点评的数据进行爬取并保存到 mongodb 数据库和mysql数据库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  1,174
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  7
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、首先准备我们需要的库</p>
<pre><code>1、requests//用来请求网页

2、json//用来解析json数据，用于把json数据转换为字典

3、re//利用正则对字符串查找

3、pyquery//利用css查找

4、pymongo//存取pymongo

5、MySQLdb//存取mysql
</code></pre><p>创建一个配置文件config.py用于存储数据库的密码</p>
<pre><code>MYSQL_HOST=&apos;localhost&apos;
MYSQL_USER=&apos;root&apos;
MYSQL_PASSWORD=&apos;&apos;
MYSQL_DB=&apos;test&apos;
MOGO_URL=&apos;localhost&apos;
MOGO_DB=&apos;nuomi&apos;
MOGO_TABLE=&apos;product&apos;
MOGO_DB_M=&apos;meituan&apos;
MOGO_TABLE_M=&apos;product&apos;
MOGO_DB_D=&apos;dazhong&apos;
MOGO_TABLE_D=&apos;product&apos;
</code></pre><p>二、百度糯米</p>
<p>1、获取全国的url</p>
<pre><code>def get_city():
    url=&apos;https://www.nuomi.com/pcindex/main/changecity&apos;
    response=requests.get(url)
    response.encoding=&apos;utf-8&apos;
    doc=pq(response.text)
    items=doc(&apos;.city-list .cities li&apos;).items()
    for item in items:
        product={
            &apos;city&apos;:item.find(&apos;a&apos;).text(),
            &apos;url&apos;:&apos;https:&apos;+item.find(&apos;a&apos;).attr(&apos;href&apos;)
        }
        get_pase(product[&apos;url&apos;],keyword)
</code></pre><p>2、通过关键字搜索商品</p>
<pre><code>def get_pase(url,keyword):
    head={
        &apos;k&apos;:keyword,
    }
    urls=url+&apos;/search?&apos;+urlencode(head)
    response=requests.get(urls)
    response.encoding = &apos;utf-8&apos;
    req=re.findall(&apos;noresult-tip&apos;,response.text)
    if req:
        print(&apos;抱歉,没有找到你搜索的内容&apos;)
    else:
        req=r&apos;&lt;a href=&quot;(.*?)&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;.*?&quot; class=&quot;shop-infoo-list-item-img&quot; /&gt;&lt;/a&gt;&apos;
        url_req=re.findall(req,response.text)
        for i in url_req:
            url_pase=&apos;https:&apos;+i
            get_pase_url(url_pase)
        req=r&apos;&lt;a href=&quot;(.*?)&quot; .*? class=&quot;ui-pager-normal&quot; .*?&lt;/a&gt;&apos;
        url_next=re.findall(req,response.text)
        for i in url_next:
            url_pases=url+i
            get_pase_url(url_pases)
</code></pre><p>3、获取商品页的商品信息</p>
<pre><code>def get_pase_url(url):
    response=requests.get(url)
    response.encoding = &apos;utf-8&apos;
    doc=pq(response.text)
    product={
        &apos;title&apos;:doc(&apos;.shop-box .shop-title&apos;).text(),
        &apos;score&apos;:doc(&apos;body &gt; div.main-container &gt; div.shop-box &gt; p &gt; span.score&apos;).text(),
        &apos;price&apos;:doc(&apos;.shop-info .price&apos;).text(),
        &apos;location&apos;:doc(&apos;.item .detail-shop-address&apos;).text(),
        &apos;phone&apos;:doc(&apos;body &gt; div.main-container &gt; div.shop-box &gt; ul &gt; li:nth-child(2) &gt; p&apos;).text(),
        &apos;time&apos;:doc(&apos;body &gt; div.main-container &gt; div.shop-box &gt; ul &gt; li:nth-child(3) &gt; p&apos;).text(),
        &apos;tuijian&apos;:doc(&apos;body &gt; div.main-container &gt; div.shop-box &gt; ul &gt; li:nth-child(4) &gt; p&apos;).text()
    }
    print(product)
    save_mysql(product)
    #save_mongodb(product)
</code></pre><p>4、保存到数据库中</p>
<pre><code>def save_mysql(product):
    conn=MySQLdb.connect(MYSQL_HOST,MYSQL_USER,MYSQL_PASSWORD,MYSQL_DB,charset=&apos;utf8&apos;)
    cursor = conn.cursor()
    cursor.execute(&quot;insert into nuomi(title,score,price,location,phone,time,tuijian) values(&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;)&quot;.format(product[&apos;title&apos;] , product[&apos;score&apos;] , product[&apos;price&apos;] , product[&apos;location&apos;] , product[&apos;phone&apos;] ,product[&apos;time&apos;] , product[&apos;tuijian&apos;]))
    print(&apos;成功存入数据库&apos;,product)
def save_mongodb(result):
    client=pymongo.MongoClient(MOGO_URL)
    db=client[MOGO_DB]
    try:
        if db[MOGO_TABLE].insert(result):
            print(&apos;保存成功&apos;,result)
    except Exception:
        print(&apos;保存失败&apos;,result)
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/%E7%99%BE%E5%BA%A6%E7%B3%AF%E7%B1%B3.jpg?raw=true" alt="image"></p>
<p>二、美团</p>
<p>1、获取全国的url</p>
<pre><code>def get_city():
    url=&apos;http://www.meituan.com/changecity/&apos;
    response=requests.get(url)
    response.encoding=&apos;utf-8&apos;
    doc=pq(response.text)
    items=doc(&apos;.city-area .cities .city&apos;).items()
    for item in items:
        product={
            &apos;url&apos;:&apos;http:&apos;+item.attr(&apos;href&apos;),
            &apos;city&apos;:item.text()
        }
        get_url_number(product[&apos;url&apos;])
</code></pre><p>2、通过关键字搜索商品</p>
<pre><code>def get_url_number(url):
    try:
        response=requests.get(url)
        req=r&apos;{&quot;currentCity&quot;:{&quot;id&quot;:(.*?),&quot;name&quot;:&quot;.*?&quot;,&quot;pinyin&quot;:&apos;
        number_url=re.findall(req,response.text)
        for code in range(0,500,32):
            url=&apos;http://apimobile.meituan.com/group/v4/poi/pcsearch/{}?limit=32&amp;offset={}&amp;q={}&apos;.format(number_url[0],code,keyword)
            response=requests.get(url)
            data=json.loads(response.text)
            imageUrl=data[&apos;data&apos;][&apos;searchResult&apos;][0][&apos;imageUrl&apos;]
            address=data[&apos;data&apos;][&apos;searchResult&apos;][0][&apos;address&apos;]
            lowestprice=data[&apos;data&apos;][&apos;searchResult&apos;][0][&apos;lowestprice&apos;]
            title=data[&apos;data&apos;][&apos;searchResult&apos;][0][&apos;title&apos;]
            url_id=data[&apos;data&apos;][&apos;searchResult&apos;][0][&apos;id&apos;]
            product={
                &apos;url_id&apos;:url_id,
                &apos;imageUrl&apos;:imageUrl,
                &apos;address&apos;:address,
                &apos;lowestprice&apos;:lowestprice,
                &apos;title&apos;:title
            }
            save_mysql(product)
    except Exception:
        return None
</code></pre><p>3、保存到数据库中</p>
<pre><code>def save_mysql(product):
    conn=MySQLdb.connect(MYSQL_HOST,MYSQL_USER,MYSQL_PASSWORD,MYSQL_DB,charset=&apos;utf8&apos;)
    cursor = conn.cursor()
    cursor.execute(&quot;insert into meituan(url_id,imageUrl,address,lowestprice,title) values(&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;)&quot;.format(product[&apos;url_id&apos;], product[&apos;imageUrl&apos;], product[&apos;address&apos;], product[&apos;lowestprice&apos;], product[&apos;title&apos;]))
    print(&apos;成功存入数据库&apos;,product)
def save_mongodb(result):
    client=pymongo.MongoClient(MOGO_URL)
    db=client[MOGO_DB_M]
    try:
        if db[MOGO_TABLE_M].insert(result):
            print(&apos;保存成功&apos;,result)
    except Exception:
        print(&apos;保存失败&apos;,result)
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/%E7%BE%8E%E5%9B%A2.jpg?raw=true" alt="image"></p>
<p>三、大众点评</p>
<p>1、获取全国的url</p>
<pre><code>def get_url_city_id():
    url = &apos;https://www.dianping.com/ajax/citylist/getAllDomesticCity&apos;
    headers = {
        &apos;User-Agent&apos;: &apos;Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/64.0.3282.186Safari/537.36&apos; ,

    }
    response = requests.get(url , headers=headers)
    data=json.loads(response.text)
    for i in range(1,35):
        url_data=data[&apos;cityMap&apos;][str(i)]
        for item in url_data:
            product={
                &apos;cityName&apos;:item[&apos;cityName&apos;],
                &apos;cityId&apos;:item[&apos;cityId&apos;],
                &apos;cityEnName&apos;:item[&apos;cityEnName&apos;]
            }
            get_url_keyword(product)
            break
</code></pre><p>2、通过关键字搜索商品</p>
<pre><code>def get_url_keyword(product):
    urls = &apos;https://www.dianping.com/search/keyword/{}/0_%{}&apos;.format(product[&apos;cityId&apos;], keyword)
    headers = {
        &apos;User-Agent&apos;: &apos;Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/64.0.3282.186Safari/537.36&apos; ,

    }
    response = requests.get(urls, headers=headers)
    req=r&apos;data-hippo-type=&quot;shop&quot; title=&quot;.*?&quot; target=&quot;_blank&quot; href=&quot;(.*?)&quot;&apos;
    data=re.findall(req,response.text)
    for url in data:
        get_url_data(url)
</code></pre><p>3、获取商品页的商品信息</p>
<pre><code>def get_url_data(url):
    headers= {
        &apos;User-Agent&apos;: &apos;Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/64.0.3282.186Safari/537.36&apos; ,
        &apos;Host&apos;: &apos;www.dianping.com&apos;,
        &apos;Pragma&apos;: &apos;no - cache&apos;,
        &apos;Upgrade - Insecure - Requests&apos;: &apos;1&apos;
    }
    response = requests.get(url,headers=headers)
    doc=pq(response.text)
    title=doc(&apos;#basic-info &gt; h1&apos;).text().replace(&apos;\n&apos;,&apos;&apos;).replace(&apos;\xa0&apos;,&apos;&apos;)
    avgPriceTitle=doc(&apos;#avgPriceTitle&apos;).text()
    taste=doc(&apos;#comment_score &gt; span:nth-of-type(1)&apos;).text()
    Environmental=doc(&apos;#comment_score &gt; span:nth-of-type(2)&apos;).text()
    service=doc(&apos;#comment_score &gt; span:nth-of-type(3)&apos;).text()
    street_address=doc(&apos;#basic-info &gt; div.expand-info.address &gt; span.item&apos;).text()
    tel=doc(&apos;#basic-info &gt; p &gt; span.item&apos;).text()
    info_name=doc(&apos;#basic-info &gt; div.promosearch-wrapper &gt; p &gt; span&apos;).text()
    time=doc(&apos;#basic-info &gt; div.other.J-other &gt; p:nth-of-type(1) &gt; span.item&apos;).text()
    product={
        &apos;title&apos;:title,
        &apos;avgPriceTitle&apos;:avgPriceTitle,
        &apos;taste&apos;: taste ,
        &apos;Environmental&apos;:Environmental,
        &apos;service&apos;: service ,
        &apos;street_address&apos;:street_address,
        &apos;tel&apos;: tel ,
        &apos;info_name&apos;:info_name,
        &apos;time&apos;:time
    }
    save_mysql(product)
</code></pre><p>3、保存到数据库中</p>
<pre><code>def save_mysql(product):
    conn=MySQLdb.connect(MYSQL_HOST,MYSQL_USER,MYSQL_PASSWORD,MYSQL_DB,charset=&apos;utf8&apos;)
    cursor=conn.cursor()
    cursor.execute(&quot;insert into dazhong(title,avgPriceTitle,taste,Environmental,service,street_address,tel,info_name,time) values(&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;,&apos;{}&apos;)&quot;.format(product[&apos;title&apos;],product[&apos;avgPriceTitle&apos;],product[&apos;taste&apos;],product[&apos;Environmental&apos;],product[&apos;service&apos;],product[&apos;street_address&apos;],product[&apos;tel&apos;],product[&apos;info_name&apos;],product[&apos;time&apos;]))
    print(&apos;成功存入数据库&apos; , product)
def save_mogodb(product):
    client=pymongo.MongoClient(MOGO_URL)
    db=client[MOGO_DB_D]
    try:
        if db[MOGO_TABLE_D].insert(product):
            print(&apos;保存成功&apos;,product)
    except Exception:
        print(&apos;保存失败&apos;,product)
</code></pre><p>详细的描述可以访问我的Github <a href="https://github.com/TomorrowLi/meituan-nuomi-dazhong.git" target="_blank" rel="noopener">TomorrowLi</a> 里面有我的源码</p>

          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/loginZhihu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/loginZhihu/" itemprop="url">最新的模拟知乎登陆</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  882
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&#160;&#160;&#160;&#160;首先我们知道随着知乎页面的不断改版，以前的模拟登陆以不能用了，以下是对知乎改版之后的最新登陆方法</p>
<p>一、首先我们所需要的库</p>
<pre><code>import requests
import time
import re
#用于下载验证码图片
import base64
#通过 Hmac 算法计算返回签名。实际是几个固定字符串加时间戳
import hmac
import hashlib
import json
import matplotlib.pyplot as plt
#保存cookie
from http import cookiejar
#打开图片
from PIL import Image
</code></pre><p>二、所需要的头信息</p>
<pre><code>#所需要的头部信息
HEADERS = {
&apos;Connection&apos;: &apos;keep-alive&apos;,
&apos;Host&apos;: &apos;www.zhihu.com&apos;,
&apos;Referer&apos;: &apos;https://www.zhihu.com/&apos;,
&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 &apos;
              &apos;(KHTML, like Gecko) Chrome/56.0.2924.87 Mobile Safari/537.36&apos;
}
#登陆使的url
LOGIN_URL = &apos;https://www.zhihu.com/signup&apos;
LOGIN_API = &apos;https://www.zhihu.com/api/v3/oauth/sign_in&apos;
FORM_DATA = {
    #客户端id基本不会改变
    &apos;client_id&apos;: &apos;c3cef7c66a1843f8b3a9e6a1e3160e20&apos;,
    &apos;grant_type&apos;: &apos;password&apos;,
    &apos;source&apos;: &apos;com.zhihu.web&apos;,
    &apos;username&apos;: &apos;用户名&apos;,
    &apos;password&apos;: &apos;密码&apos;,
    # 改为&apos;cn&apos;是倒立汉字验证码
    &apos;lang&apos;: &apos;en&apos;,
    &apos;ref_source&apos;: &apos;homepage&apos;
}
</code></pre><p>&#160;&#160;&#160;&#160;要想登陆成功，header里必须还要俩个参数</p>
<pre><code>#经过大量的验证，这个参数必须有，这个值基本不变
&apos;authorization&apos;: &apos;oauth c3cef7c66a1843f8b3a9e6a1e3160e20&apos;,
#X-Xsrftoken则是防 Xsrf 跨站的 Token 认证，在Response Headers的Set-Cookie字段中可以找到。所以我们需要先请求一次登录页面，然后用正则把这一段匹配出来。注意需要无 Cookies 请求才会返回 Set-Cookie
&apos;X-Xsrftoken&apos;: _xsrf
</code></pre><p><img src="https://github.com/TomorrowLi/MarkdownImage/blob/master/set_cookie%E6%8D%95%E8%8E%B7.PNG?raw=true" alt="Set-Cookie"></p>
<p>&#160;&#160;&#160;&#160;要想登陆成功，form_data也里必须还要俩个参数</p>
<pre><code>&apos;captcha&apos;: 验证码,
&apos;timestamp&apos;: 时间戳,
&apos;signature&apos;: 是通过 Hmac 算法对几个固定值和时间戳进行加密
</code></pre><p>&#160;&#160;&#160;&#160;timestamp 时间戳，这个很好解决，区别是这里是13位整数，Python 生成的整数部分只有10位，需要额外乘以1000</p>
<pre><code>timestamp = str(int(time.time()*1000))
</code></pre><p>&#160;&#160;&#160;&#160;captcha 验证码，是通过 GET 请求单独的 API 接口返回是否需要验证码（无论是否需要，都要请求一次），如果是 True 则需要再次 PUT 请求获取图片的 base64 编码。</p>
<pre><code>def _get_captcha(self, headers):
   &quot;&quot;&quot;
   请求验证码的 API 接口，无论是否需要验证码都需要请求一次
   如果需要验证码会返回图片的 base64 编码
   根据头部 lang 字段匹配验证码，需要人工输入
   :param headers: 带授权信息的请求头部
   :return: 验证码的 POST 参数
   &quot;&quot;&quot;
   lang = headers.get(&apos;lang&apos;, &apos;en&apos;)
   if lang == &apos;cn&apos;:
       api = &apos;https://www.zhihu.com/api/v3/oauth/captcha?lang=cn&apos;
   else:
       api = &apos;https://www.zhihu.com/api/v3/oauth/captcha?lang=en&apos;
   resp = self.session.get(api, headers=headers)
   show_captcha = re.search(r&apos;true&apos;, resp.text)
   if show_captcha:
       put_resp = self.session.put(api, headers=headers)
       img_base64 = re.findall(
           r&apos;&quot;img_base64&quot;:&quot;(.+)&quot;&apos;, put_resp.text, re.S)[0].replace(r&apos;\n&apos;, &apos;&apos;)
       with open(&apos;./captcha.jpg&apos;, &apos;wb&apos;) as f:
           f.write(base64.b64decode(img_base64))
       img = Image.open(&apos;./captcha.jpg&apos;)
       if lang == &apos;cn&apos;:
           plt.imshow(img)
           print(&apos;点击所有倒立的汉字，按回车提交&apos;)
           points = plt.ginput(7)
           capt = json.dumps({&apos;img_size&apos;: [200, 44],
                              &apos;input_points&apos;: [[i[0]/2, i[1]/2] for i in points]})
       else:
           img.show()
           capt = input(&apos;请输入图片里的验证码：&apos;)
       # 这里必须先把参数 POST 验证码接口
       self.session.post(api, data={&apos;input_text&apos;: capt}, headers=headers)
       return capt
   return &apos;&apos;
</code></pre><p>&#160;&#160;&#160;&#160;signature 通过 Crtl+Shift+F 搜索找到是在一个 JS 里生成的，是通过 Hmac 算法对几个固定值和时间戳进行加密，那么只需要在 Python 里也模拟一次这个加密即可。</p>
<pre><code>def _get_signature(self, timestamp):
    &quot;&quot;&quot;
    通过 Hmac 算法计算返回签名
    实际是几个固定字符串加时间戳
    :param timestamp: 时间戳
    :return: 签名
    &quot;&quot;&quot;
    ha = hmac.new(b&apos;d1b964811afb40118a12068ff74a12f4&apos;, digestmod=hashlib.sha1)
    grant_type = self.login_data[&apos;grant_type&apos;]
    client_id = self.login_data[&apos;client_id&apos;]
    source = self.login_data[&apos;source&apos;]
    ha.update(bytes((grant_type + client_id + source + timestamp), &apos;utf-8&apos;))
    return ha.hexdigest()
</code></pre><p>文章出自   <a href="https://zhuanlan.zhihu.com/p/34073256" target="_blank" rel="noopener">知乎</a></p>

          
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/javaEE_day13_Servlet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/javaEE_day13_Servlet/" itemprop="url">有关servlet的几种面试题</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/javaEE/" itemprop="url" rel="index">
                    <span itemprop="name">javaEE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  613
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  2
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="1、Post和Get的区别"><a href="#1、Post和Get的区别" class="headerlink" title="1、Post和Get的区别"></a>1、Post和Get的区别</h2><pre><code>Post:
    请求参数在请求体中

    请求的url的长度没有限制

    较为安全
Get：
    亲求参数在请求行中

    请求的url长度没有限制

    相对不安全
中文乱码问题：
        * get方式：tomcat 8 已经将get方式乱码问题解决了
        * post方式：会乱码
            * 解决：在获取参数前，设置request的编码request.setCharacterEncoding(&quot;utf-8&quot;);
</code></pre>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2021/07/18/javaEE_day13_Servlet/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/18/javaEE_day12_mysqlPool/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TomorrowLi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TomorrowLi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/07/18/javaEE_day12_mysqlPool/" itemprop="url">javaEE之几种常见的连接池</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-07-18T09:44:26+08:00">
                2021-07-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/javaEE/" itemprop="url" rel="index">
                    <span itemprop="name">javaEE</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  806
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h2 id="1、c3p0连接池"><a href="#1、c3p0连接池" class="headerlink" title="1、c3p0连接池"></a>1、c3p0连接池</h2><pre><code>* 步骤：
        1. 导入jar包 (两个) 
             c3p0-0.9.5.2.jar 
            mchange-commons-java-0.2.12.jar ，
            * 不要忘记导入数据库驱动jar包
        2. 定义配置文件：

            * 名称： c3p0.properties 或者 c3p0-config.xml（文件名称必须是这两个中其中一个）

            * 路径：直接将文件放在src目录下即可。自动加载，不需要用getClassLoader()加载配置文件路径

        3. 创建核心对象 数据库连接池对象     ComboPooledDataSource
        4. 获取连接： getConnection

    * 代码：
         //1.创建数据库连接池对象
        DataSource ds  = new ComboPooledDataSource();
        //2. 获取连接对象
        Connection conn = ds.getConnection();
</code></pre>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2021/07/18/javaEE_day12_mysqlPool/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>
    
    
    
    
    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="TomorrowLi">
            
              <p class="site-author-name" itemprop="name">TomorrowLi</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/TomorrowLi" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://mail.qq.com/" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-E-Mail"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="https://www.zhihu.com/people/pai-huai-zai-yun-duan/activities" target="_blank" title="ZhiHu">
                    
                      <i class="fa fa-fw fa-globe"></i>ZhiHu</a>
                </span>
              
            
          </div>

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                推荐阅读
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://cuiqingcai.com/" title="静觅" target="_blank">静觅</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.liaoxuefeng.com/" title="廖雪峰python教程" target="_blank">廖雪峰python教程</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://stormzhang.com" title="stormzhang" target="_blank">stormzhang</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://howiezhao.github.io/" title="Howiezhao" target="_blank">Howiezhao</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://pyzh.readthedocs.io/en/latest/index.html" title="PyZh" target="_blank">PyZh</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://pythonguidecn.readthedocs.io/zh/latest/" title="Python最佳实践指南" target="_blank">Python最佳实践指南</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TomorrowLi</span>

  
</div>


  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
   </span>
  </div>
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共17.8k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  









<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
